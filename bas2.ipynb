{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495bd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de819529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "currency_data = yf.download('USDINR=X', start='2020-01-01', end='2023-01-01')\n",
    "currency_data = currency_data[['Close']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(currency_data.values)\n",
    "\n",
    "def create_dataset(data, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(time_step, len(data)):\n",
    "        X.append(data[i - time_step:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_dataset(scaled_data)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0b0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "def objective_function(hyperparams):\n",
    "    lstm_units = int(hyperparams[0])\n",
    "    learning_rate = hyperparams[1]\n",
    "    batch_size = int(hyperparams[2])\n",
    "    epochs = int(hyperparams[3])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X.shape[1], 1)))\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True))\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    mse = model.evaluate(X, y, verbose=0)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAS optimizer\n",
    "class BASOptimizer:\n",
    "    def __init__(self, objective_func, dim, bounds, max_iter=30):\n",
    "        self.objective_func = objective_func\n",
    "        self.dim = dim\n",
    "        self.bounds = bounds\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def optimize(self):\n",
    "        x = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1])\n",
    "        d = 0.3\n",
    "        delta = 0.1\n",
    "        best_score = float('inf')\n",
    "        best_params = x.copy()\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            b = np.random.randn(self.dim)\n",
    "            b = b / np.linalg.norm(b)\n",
    "\n",
    "            xr = np.clip(x + d * b, self.bounds[:, 0], self.bounds[:, 1])\n",
    "            xl = np.clip(x - d * b, self.bounds[:, 0], self.bounds[:, 1])\n",
    "\n",
    "            fr = self.objective_func(xr)\n",
    "            fl = self.objective_func(xl)\n",
    "\n",
    "            x = np.clip(x + delta * b * np.sign(fr - fl), self.bounds[:, 0], self.bounds[:, 1])\n",
    "            f = self.objective_func(x)\n",
    "\n",
    "            if f < best_score:\n",
    "                best_score = f\n",
    "                best_params = x.copy()\n",
    "\n",
    "            print(f\"Iteration {t+1}/{self.max_iter} - Best MSE: {best_score:.8f}\")\n",
    "            d = 0.95 * d + 0.01\n",
    "            delta *= 0.95\n",
    "\n",
    "        return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dac80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameter search bounds\n",
    "bounds = np.array([\n",
    "    [10, 200],       # LSTM units\n",
    "    [1e-4, 1e-2],    # Learning rate\n",
    "    [16, 64],        # Batch size\n",
    "    [5, 50]          # Epochs\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1c849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100 - Best MSE: 0.00077611\n",
      "Iteration 2/100 - Best MSE: 0.00077611\n",
      "Iteration 3/100 - Best MSE: 0.00077611\n",
      "Iteration 4/100 - Best MSE: 0.00077611\n",
      "Iteration 5/100 - Best MSE: 0.00077611\n",
      "Iteration 6/100 - Best MSE: 0.00077611\n",
      "Iteration 7/100 - Best MSE: 0.00063939\n",
      "Iteration 8/100 - Best MSE: 0.00063939\n",
      "Iteration 9/100 - Best MSE: 0.00063939\n",
      "Iteration 10/100 - Best MSE: 0.00063939\n",
      "Iteration 11/100 - Best MSE: 0.00063939\n",
      "Iteration 12/100 - Best MSE: 0.00063939\n",
      "Iteration 13/100 - Best MSE: 0.00062900\n",
      "Iteration 14/100 - Best MSE: 0.00062900\n",
      "Iteration 15/100 - Best MSE: 0.00062900\n",
      "Iteration 16/100 - Best MSE: 0.00062900\n",
      "Iteration 17/100 - Best MSE: 0.00062900\n",
      "Iteration 18/100 - Best MSE: 0.00058435\n",
      "Iteration 19/100 - Best MSE: 0.00058435\n",
      "Iteration 20/100 - Best MSE: 0.00058435\n",
      "Iteration 21/100 - Best MSE: 0.00058435\n",
      "Iteration 22/100 - Best MSE: 0.00058435\n",
      "Iteration 23/100 - Best MSE: 0.00058435\n",
      "Iteration 24/100 - Best MSE: 0.00058435\n",
      "Iteration 25/100 - Best MSE: 0.00058435\n",
      "Iteration 26/100 - Best MSE: 0.00058435\n",
      "Iteration 27/100 - Best MSE: 0.00058435\n",
      "Iteration 28/100 - Best MSE: 0.00058435\n",
      "Iteration 29/100 - Best MSE: 0.00058435\n",
      "Iteration 30/100 - Best MSE: 0.00058435\n",
      "Iteration 31/100 - Best MSE: 0.00058435\n",
      "Iteration 32/100 - Best MSE: 0.00058435\n",
      "Iteration 33/100 - Best MSE: 0.00058435\n",
      "Iteration 34/100 - Best MSE: 0.00058435\n",
      "Iteration 35/100 - Best MSE: 0.00058435\n",
      "Iteration 36/100 - Best MSE: 0.00058435\n",
      "Iteration 37/100 - Best MSE: 0.00058435\n",
      "Iteration 38/100 - Best MSE: 0.00058435\n",
      "Iteration 39/100 - Best MSE: 0.00058435\n",
      "Iteration 40/100 - Best MSE: 0.00058435\n",
      "Iteration 41/100 - Best MSE: 0.00058435\n",
      "Iteration 42/100 - Best MSE: 0.00058435\n",
      "Iteration 43/100 - Best MSE: 0.00058435\n",
      "Iteration 44/100 - Best MSE: 0.00058435\n",
      "Iteration 45/100 - Best MSE: 0.00058435\n",
      "Iteration 46/100 - Best MSE: 0.00058435\n",
      "Iteration 47/100 - Best MSE: 0.00058435\n",
      "Iteration 48/100 - Best MSE: 0.00058435\n",
      "Iteration 49/100 - Best MSE: 0.00058435\n",
      "Iteration 50/100 - Best MSE: 0.00058435\n",
      "Iteration 51/100 - Best MSE: 0.00058435\n",
      "Iteration 52/100 - Best MSE: 0.00058435\n",
      "Iteration 53/100 - Best MSE: 0.00058435\n",
      "Iteration 54/100 - Best MSE: 0.00058435\n",
      "Iteration 55/100 - Best MSE: 0.00058435\n",
      "Iteration 56/100 - Best MSE: 0.00058435\n",
      "Iteration 57/100 - Best MSE: 0.00058435\n",
      "Iteration 58/100 - Best MSE: 0.00058435\n",
      "Iteration 59/100 - Best MSE: 0.00058435\n",
      "Iteration 60/100 - Best MSE: 0.00058435\n",
      "Iteration 61/100 - Best MSE: 0.00058435\n",
      "Iteration 62/100 - Best MSE: 0.00058435\n",
      "Iteration 63/100 - Best MSE: 0.00058435\n",
      "Iteration 64/100 - Best MSE: 0.00058435\n",
      "Iteration 65/100 - Best MSE: 0.00058435\n",
      "Iteration 66/100 - Best MSE: 0.00058435\n",
      "Iteration 67/100 - Best MSE: 0.00058435\n",
      "Iteration 68/100 - Best MSE: 0.00058435\n",
      "Iteration 69/100 - Best MSE: 0.00058435\n",
      "Iteration 70/100 - Best MSE: 0.00058435\n",
      "Iteration 71/100 - Best MSE: 0.00058435\n",
      "Iteration 72/100 - Best MSE: 0.00058435\n",
      "Iteration 73/100 - Best MSE: 0.00058435\n",
      "Iteration 74/100 - Best MSE: 0.00058435\n",
      "Iteration 75/100 - Best MSE: 0.00058435\n",
      "Iteration 76/100 - Best MSE: 0.00058435\n",
      "Iteration 77/100 - Best MSE: 0.00058435\n",
      "Iteration 78/100 - Best MSE: 0.00058435\n",
      "Iteration 79/100 - Best MSE: 0.00058435\n",
      "Iteration 80/100 - Best MSE: 0.00058435\n",
      "Iteration 81/100 - Best MSE: 0.00058435\n",
      "Iteration 82/100 - Best MSE: 0.00058435\n",
      "Iteration 83/100 - Best MSE: 0.00058435\n",
      "Iteration 84/100 - Best MSE: 0.00058435\n",
      "Iteration 85/100 - Best MSE: 0.00058435\n",
      "Iteration 86/100 - Best MSE: 0.00058435\n",
      "Iteration 87/100 - Best MSE: 0.00058435\n",
      "Iteration 88/100 - Best MSE: 0.00057649\n",
      "Iteration 89/100 - Best MSE: 0.00057649\n",
      "Iteration 90/100 - Best MSE: 0.00057649\n",
      "Iteration 91/100 - Best MSE: 0.00057649\n",
      "Iteration 92/100 - Best MSE: 0.00057649\n",
      "Iteration 93/100 - Best MSE: 0.00057649\n",
      "Iteration 94/100 - Best MSE: 0.00057649\n",
      "Iteration 95/100 - Best MSE: 0.00057362\n",
      "Iteration 96/100 - Best MSE: 0.00057362\n",
      "Iteration 97/100 - Best MSE: 0.00057362\n",
      "Iteration 98/100 - Best MSE: 0.00057362\n",
      "Iteration 99/100 - Best MSE: 0.00057362\n",
      "Iteration 100/100 - Best MSE: 0.00057362\n",
      "Best Hyperparameters: [1.95573668e+02 4.34448776e-03 1.84571111e+01 3.68130319e+01]\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "optimizer = BASOptimizer(objective_function, dim=4, bounds=bounds, max_iter=100)\n",
    "best_params, best_score = optimizer.optimize()\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fa965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model using optimized hyperparameters\n",
    "final_units = int(best_params[0])\n",
    "final_lr = float(best_params[1])\n",
    "final_batch = int(best_params[2])\n",
    "final_epochs = int(best_params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6d022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(tf.keras.layers.Input(shape=(X.shape[1], 1)))\n",
    "final_model.add(LSTM(units=final_units, return_sequences=True))\n",
    "final_model.add(LSTM(units=final_units, return_sequences=False))\n",
    "final_model.add(Dropout(0.2))\n",
    "final_model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450d0b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.0840\n",
      "Epoch 2/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0019\n",
      "Epoch 3/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0025\n",
      "Epoch 4/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022\n",
      "Epoch 5/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0016\n",
      "Epoch 6/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0020\n",
      "Epoch 7/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0017\n",
      "Epoch 8/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0019\n",
      "Epoch 9/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0018\n",
      "Epoch 10/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0014\n",
      "Epoch 11/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0018\n",
      "Epoch 12/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.0013\n",
      "Epoch 13/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0014\n",
      "Epoch 14/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0019\n",
      "Epoch 15/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0020\n",
      "Epoch 16/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0013\n",
      "Epoch 17/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0014\n",
      "Epoch 18/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0012\n",
      "Epoch 19/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0012\n",
      "Epoch 20/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0013\n",
      "Epoch 21/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0012\n",
      "Epoch 22/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0012\n",
      "Epoch 23/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0012\n",
      "Epoch 24/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0011\n",
      "Epoch 25/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0011\n",
      "Epoch 26/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0011\n",
      "Epoch 27/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0014\n",
      "Epoch 28/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014\n",
      "Epoch 29/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0010\n",
      "Epoch 30/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 9.9276e-04\n",
      "Epoch 31/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0011\n",
      "Epoch 32/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 9.3675e-04\n",
      "Epoch 33/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011\n",
      "Epoch 34/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0011\n",
      "Epoch 35/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0010\n",
      "Epoch 36/36\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 9.2748e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c565c4d700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=final_lr), loss='mean_squared_error')\n",
    "final_model.fit(X, y, epochs=final_epochs, batch_size=final_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0039016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_lstm_currency_model.keras\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "final_model.save(\"optimized_lstm_currency_model.keras\")\n",
    "print(\"optimized_lstm_currency_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
